[Skip to content](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#start-of-content)

You signed in with another tab or window. [Reload](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example) to refresh your session.Dismiss alert

{{ message }}

[GetStream](https://github.com/GetStream)/ **[Vision-Agents](https://github.com/GetStream/Vision-Agents)** Public

- [Notifications](https://github.com/login?return_to=%2FGetStream%2FVision-Agents) You must be signed in to change notification settings
- [Fork\\
116](https://github.com/login?return_to=%2FGetStream%2FVision-Agents)
- [Star\\
979](https://github.com/login?return_to=%2FGetStream%2FVision-Agents)


## Collapse file tree

## Files

main

Search this repository

/

# 02\_golf\_coach\_example

/

Copy path

## Directory actions

## More options

More options

## Directory actions

## More options

More options

## Latest commit

[![tschellenbach](https://avatars.githubusercontent.com/u/265409?v=4&size=40)](https://github.com/tschellenbach)[tschellenbach](https://github.com/GetStream/Vision-Agents/commits?author=tschellenbach)

[example cleanup (](https://github.com/GetStream/Vision-Agents/commit/27559dc6987c6ee28fef683db81bf777cf3a2982) [#189](https://github.com/GetStream/Vision-Agents/pull/189) [)](https://github.com/GetStream/Vision-Agents/commit/27559dc6987c6ee28fef683db81bf777cf3a2982)

failure

4 days agoNov 14, 2025

[27559dc](https://github.com/GetStream/Vision-Agents/commit/27559dc6987c6ee28fef683db81bf777cf3a2982) · 4 days agoNov 14, 2025

## History

[History](https://github.com/GetStream/Vision-Agents/commits/main/examples/02_golf_coach_example)

Open commit details

[View commit history for this file.](https://github.com/GetStream/Vision-Agents/commits/main/examples/02_golf_coach_example)

/

# 02\_golf\_coach\_example

/

Top

## Folders and files

| Name | Name | Last commit message | Last commit date |
| --- | --- | --- | --- |
| ### parent directory<br> [..](https://github.com/GetStream/Vision-Agents/tree/main/examples) |
| [README.md](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/README.md "README.md") | [README.md](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/README.md "README.md") | [Add example readme (](https://github.com/GetStream/Vision-Agents/commit/c55fd3c1534ce3e930b4e518cf1f73b2b6359322 "Add example readme (#84)  * Add guide for simple agent  * add urls  * Add readmes to both examples  * minor cleanup") [#84](https://github.com/GetStream/Vision-Agents/pull/84) [)](https://github.com/GetStream/Vision-Agents/commit/c55fd3c1534ce3e930b4e518cf1f73b2b6359322 "Add example readme (#84)  * Add guide for simple agent  * add urls  * Add readmes to both examples  * minor cleanup") | last monthOct 9, 2025 |
| [\_\_init\_\_.py](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/__init__.py "__init__.py") | [\_\_init\_\_.py](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/__init__.py "__init__.py") | [cleanup](https://github.com/GetStream/Vision-Agents/commit/b24d30ae7db92900716cc481881a78e3ebaf9924 "cleanup") | 2 months agoSep 24, 2025 |
| [golf\_coach.md](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/golf_coach.md "golf_coach.md") | [golf\_coach.md](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/golf_coach.md "golf_coach.md") | [fix: added shared video forwarder (](https://github.com/GetStream/Vision-Agents/commit/2d152e120ece36c29b43e283f3929e4d13f4c860 "fix: added shared video forwarder (#64)  * added shared video forwarder  * fix: prevent image processor loop from competing with video processors for frames  * fix: add **kwargs to Realtime._watch_video_track for type compatibility  * Update instrc  ---------  Co-authored-by: Neevash Ramdial (Nash) <mail@neevash.dev>") [#64](https://github.com/GetStream/Vision-Agents/pull/64) [)](https://github.com/GetStream/Vision-Agents/commit/2d152e120ece36c29b43e283f3929e4d13f4c860 "fix: added shared video forwarder (#64)  * added shared video forwarder  * fix: prevent image processor loop from competing with video processors for frames  * fix: add **kwargs to Realtime._watch_video_track for type compatibility  * Update instrc  ---------  Co-authored-by: Neevash Ramdial (Nash) <mail@neevash.dev>") | last monthOct 3, 2025 |
| [golf\_coach\_example.py](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/golf_coach_example.py "golf_coach_example.py") | [golf\_coach\_example.py](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/golf_coach_example.py "golf_coach_example.py") | [example cleanup (](https://github.com/GetStream/Vision-Agents/commit/27559dc6987c6ee28fef683db81bf777cf3a2982 "example cleanup (#189)") [#189](https://github.com/GetStream/Vision-Agents/pull/189) [)](https://github.com/GetStream/Vision-Agents/commit/27559dc6987c6ee28fef683db81bf777cf3a2982 "example cleanup (#189)") | 4 days agoNov 14, 2025 |
| [pyproject.toml](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/pyproject.toml "pyproject.toml") | [pyproject.toml](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/pyproject.toml "pyproject.toml") | [Fix missing dependencies in examples (](https://github.com/GetStream/Vision-Agents/commit/5bc669266c0fccb69fd96bd4674fad4dbcbdb623 "Fix missing dependencies in examples (#79)  * Add missing vision-agents-plugins-smart-turn dependency to example 01  * example 02: add missing gemini deps") [#79](https://github.com/GetStream/Vision-Agents/pull/79) [)](https://github.com/GetStream/Vision-Agents/commit/5bc669266c0fccb69fd96bd4674fad4dbcbdb623 "Fix missing dependencies in examples (#79)  * Add missing vision-agents-plugins-smart-turn dependency to example 01  * example 02: add missing gemini deps") | last monthOct 9, 2025 |
| [uv.lock](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/uv.lock "uv.lock") | [uv.lock](https://github.com/GetStream/Vision-Agents/blob/main/examples/02_golf_coach_example/uv.lock "uv.lock") | [debugging](https://github.com/GetStream/Vision-Agents/commit/b5482da842b757f791886fee0990fcd3d93c2648 "debugging") | last monthOct 21, 2025 |
| View all files |

## [README.md](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example\#readme)

Outline

# Golf Coach Example

[Permalink: Golf Coach Example](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#golf-coach-example)

This example shows you how to build a real-time golf coaching AI using [Vision Agents](https://visionagents.ai/). The agent uses video processing to watch golf swings and provide feedback through voice conversation.

In this example, the AI golf coach will:

- Watches video of the user's golf swing
- Uses [YOLO](https://www.ultralytics.com/yolo) pose detection to analyze body position and movement
- Processes the video in real-time with an LLM (Large Language Model)
- Provides voice feedback on the swing technique
- Runs on Stream's low-latency edge network

This approach combines a fast object detection model (YOLO) with a full realtime AI. You can apply this pattern to other video AI use cases like sports coaching, physical therapy, workout coaching, or drone monitoring.

## Prerequisites

[Permalink: Prerequisites](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#prerequisites)

- Python 3.13 or higher
- API keys for:
  - [Gemini](https://ai.google.dev/) (for realtime LLM with vision)
  - [Stream](https://getstream.io/) (for video/audio infrastructure)
  - Alternatively: [OpenAI](https://openai.com/) (if using OpenAI Realtime instead)

## Installation

[Permalink: Installation](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#installation)

1. Install dependencies using uv:



```
uv sync
```

2. Create a `.env` file with your API keys:



```
GEMINI_API_KEY=your_gemini_key
STREAM_API_KEY=your_stream_key
STREAM_API_SECRET=your_stream_secret
```







If using OpenAI instead of Gemini, also add:



```
OPENAI_API_KEY=your_openai_key
```


## Running the Example

[Permalink: Running the Example](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#running-the-example)

Run the agent:

```
uv run golf_coach_example.py
```

The agent will:

1. Create a video call
2. Open a demo UI in your browser
3. Join the call and start watching
4. Ask you to do a golf swing
5. Analyze your swing and provide feedback

## Code Walkthrough

[Permalink: Code Walkthrough](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#code-walkthrough)

### Setting Up the Agent

[Permalink: Setting Up the Agent](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#setting-up-the-agent)

The code creates an agent with video processing capabilities:

```
agent = Agent(
    edge=getstream.Edge(),
    agent_user=User(name="AI golf coach"),
    instructions="Read @golf_coach.md",
    llm=gemini.Realtime(fps=10),
    processors=[ultralytics.YOLOPoseProcessor(model_path="yolo11n-pose.pt")],
)
```

**Components:**

- `edge`: Handles low-latency audio/video transport
- `agent_user`: Sets the agent's name and ID
- `instructions`: Loads coaching instructions from `golf_coach.md`
- `llm`: The language model that powers the conversation and video analysis
- `processors`: Video processing pipeline that runs alongside the LLM

### Understanding Processors

[Permalink: Understanding Processors](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#understanding-processors)

Processors enable the agent to analyze video in real-time. The `YOLOPoseProcessor` detects human poses and body positions in each video frame. This information is sent to the LLM so it can understand the user's body movement during the golf swing.

The `fps=10` parameter means the LLM processes 10 frames per second. Higher FPS gives more detail but costs more.

### Instructions File

[Permalink: Instructions File](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#instructions-file)

The `golf_coach.md` file contains detailed coaching guidelines. It tells the agent:

- How to behave (personality and tone)
- What to look for in a golf swing
- How to provide feedback
- Golf coaching best practices

You can modify this file to change the coaching style or add more specific guidance.

## Customization

[Permalink: Customization](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#customization)

### Change the FPS

[Permalink: Change the FPS](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#change-the-fps)

Adjust how many frames per second the LLM processes:

```
llm=gemini.Realtime(fps=5)  # Lower FPS = less expensive
llm=gemini.Realtime(fps=15)  # Higher FPS = more detailed analysis
```

### Use OpenAI Instead of Gemini

[Permalink: Use OpenAI Instead of Gemini](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#use-openai-instead-of-gemini)

Switch to OpenAI's realtime API:

```
agent = Agent(
    edge=getstream.Edge(),
    agent_user=User(name="My happy AI friend", id="agent"),
    instructions="You're a video AI assistant...",
    llm=openai.Realtime(fps=10)
)
```

Both models support video processing with YOLO.

### Modify the Coaching Style

[Permalink: Modify the Coaching Style](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#modify-the-coaching-style)

Edit the `golf_coach.md` file to change:

- The agent's personality
- The coaching focus areas
- The level of detail in feedback
- The voice and tone

### Use Different YOLO Models

[Permalink: Use Different YOLO Models](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#use-different-yolo-models)

Try other YOLO models for different use cases:

```
# For general object detection
ultralytics.YOLOProcessor(model_path="yolo11n.pt")

# For pose detection (current)
ultralytics.YOLOPoseProcessor(model_path="yolo11n-pose.pt")
```

## How It Works

[Permalink: How It Works](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#how-it-works)

1. **Video Capture**: The user's camera feeds video to the agent
2. **Pose Detection**: YOLO analyzes each frame and extracts body position data
3. **LLM Processing**: The realtime LLM receives both the video and pose data
4. **Analysis**: The LLM watches the swing and evaluates technique
5. **Feedback**: The agent speaks feedback based on coaching guidelines

## Learn More

[Permalink: Learn More](https://github.com/GetStream/Vision-Agents/tree/main/examples/02_golf_coach_example#learn-more)

- [Building a Voice AI app](https://visionagents.ai/introduction/voice-agents)
- [Building a Video AI app](https://visionagents.ai/introduction/video-agents)
- [Main Vision Agents README](https://github.com/GetStream/Vision-Agents/blob/main/README.md)
- [Simple Agent Example](https://github.com/GetStream/Vision-Agents/blob/main/examples/01_simple_agent_example) \- Start here if you're new to Vision Agents

You can’t perform that action at this time.